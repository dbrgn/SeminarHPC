\chapter{Knacken von MD5 mit OpenCL}
\rhead{Knacken von MD5 mit OpenCL}
\begin{refsection}

\chapterauthor{Danilo Bargen, Lukas Murer}

\section{Einleitung}

%- Was ist ein Hash-Algorithmus?
%- Was ist MD5?
%- Was ist Brute Force Cracking?
%- "Uberlegungen zum Keyspace
%- Zielsetzung

\subsection{Hashfunktionen}

Hashfunktionen (zu Deutsch \textit{Streuwertfunktionen}) sind in der Informatik
allgegenw"artig. Die Aufgabe einer Hashfunktion ist es, eine beliebig grosse
Eingabemenge auf eine kleine Ausgabemenge mit fester L"ange abzubilden.
Anwendungsgebiete sind beispielsweise die Integrit"atspr"ufung von Daten
(Pr"ufsummen) oder das Verschleiern von Passw"ortern (Passwort-Hashes).

Mathematisch gesehen ist eine Abbildung $h: K \rightarrow S$ eine Hashfunktion,
wenn $|K| \geq |S|$ gilt. Dabei ist $K$ die Menge der Schl"ussel und $S$ die
Menge der m"oglichen Hashwerte.

Eine der einfachsten Hashfunktionen ist die Quersumme, bei welcher die
Ziffernwerte einer Zahl summiert werden.
\[
	q(1337) = 1 + 3 + 3 + 7 = 14
\]
Weitere bekannte Hashfunktionen sind die Divisions-Rest-Methode
(Modulo-Arithmetik), CRC-Pr"ufsummen (Integrit"atspr"ufung) oder der Secure Hash
Algorithm (Kryptologie).

Die Anforderungen an eine ``gute'' Hashfunktion sind Abh"angig vom
Anwendungsbereich. Bei der ISBN-10 ist beispielsweise lediglich eine
Plausibilit"atspr"ufung in Form einer Pr"ufsumme n"otig. Bei Anwendungsf"allen
in der Kryptologie (zum Beispiel beim Hashen von Passw"ortern) sind jedoch viele
weitere Kriterien relevant. Nachfolgend werden einige davon vorgestellt.

\subsection{Eigenschaften von Hashfunktionen}

\subsubsection{Chaos}

Die Ausgabe einer chaotischen Hashfunktion sollte f"ur "ahnliche Eingabewerte
v"ollig unterschiedlich sein. Eine kleine "Anderung am Eingabewert sollte eine
grosse "Anderung im Ausgabewert zur Folge haben.

\subsubsection{Schwierige Umkehrbarkeit}

Eine schwierig umkehrbare Hashfunktion hat zum Ziel die Berechnung des
Funktionswertes m"oglichst zu vereinfachen, aber die Umkehrung dieses Ergebnisses
(berechnen des Ausgangswertes aus der Abbildung) m"oglichst zu erschweren. Anders
gesagt, es soll praktisch nicht m"oglich sein, zu einem gegebenen Hashwert $x$
eine Nachricht $m$ zu finden, f"ur welche $h(m) = x$ gilt.  Funktionen welche
diese Eigenschaft erf"ullen werden auch Einwegfunktionen genannt.

\subsubsection{Surjektivit"at}

Bei einer surjektiven Hashfunktion ist kein Ausgabewert unm"oglich, jeder kann
tats"achlich vorkommen.

\subsubsection{Kollisionsresistenz}
\label{crypto:kollisionsresistenz}

Eine Kollisionsresistente Hashfunktion sollte es erschweren, zwei Eingabewerte
zu finden die den selben Ausgabewert ergeben. Daf"ur sollten die Ausgabewerte
m"oglichst gleichverteilt auftreten.

In der Kryptologie wird zwischen schwacher und starker Kollisionsresistenz
unterschieden\cite{crypto:stephan2011kryptographie}:

\begin{itemize}
		\item Schwache Kollisionsresistenz heisst, dass es praktisch nicht m"oglich
			ist, zu einer gegebenen Nachricht $m_0$ eine zweite Nachricht $m_1$ zu finden, f"ur
			welche $h(m_0) = h(m_1)$ gilt.
		\item Starke Kollisionsresistenz heisst, dass es praktisch nicht m"oglich
			ist, zwei Nachrichten $m_0$ und $m_1$ zu finden, f"ur welche $h(m_0) =
			h(m_1)$ gilt.
\end{itemize}

\subsubsection{Effizienz}

Je nach Anwendungsfall m"ochte man effiziente oder ineffiziente Berechnungen
eines Hashwertes erzielen. W"ahrend ersteres logisch erscheint -- man m"ochte
den Algorithmus in Hard- und Software m"oglichst einfach und schnell
implementieren k"onnen -- ist letzteres auf den ersten Blick ein merkw"Urdiges
Ziel. Die Eigenschaft ist jedoch vor allem f"ur Passwort-Hash-Funktionen
relevant. Um zu verhindern dass ein Angreifer m"oglichst schnell alle m"oglichen
Passw"orter vorberechnet, m"ochte man eine Funktion welche aufw"andig und
ressourcenintensiv zu berechnen ist.

\subsection{MD5}

Der MD5 Algorithmus (Message-Digest Algorithm 5) wurde im Jahr 1991 vom
Kryptologen Ronald L. Rivest entwickelt. MD5 erzeugt zu einer beliebigen
Nachricht einen 128-Bit Hashwert.

Unter Unix-basierten Betriebssystemen kann man MD5-Werte ganz einfach auf der
Kommandozeile berechnen:

\begin{verbatim}
$ echo -n "Mathematisches Seminar" | md5sum 
47b2d986d0ae09d6504b9696e9406ca4
\end{verbatim}

Man sieht also, dass der Eingabewert ``Mathematisches Seminar'' auf den
Ausgabewert \texttt{47b2\-d986\-d0ae\-09d6\-504b\-9696\-e940\-6ca4} (in
hexadezimaler Notation) abgebildet wird. Wenn man nun nur ein einzelnes
Zeichen im Eingabestring "andert, sieht die Ausgabe v"ollig anders aus
($\rightarrow$ Chaoseigenschaft):

\begin{verbatim}
$ echo -n "Mathematisches Saminar" | md5sum 
625a5fb1280f153aa06709d70b38dfb8
\end{verbatim}

MD5 war (und ist) weit verbreitet und wurde in der Vergangenheit neben der
Integrit"atspr"ufung auch h"aufig zum Verschleiern von Passw"ortern verwendet.
Wie dies funktioniert, l"asst sich einfach an einem Praxisbeispiel
demonstrieren:

\begin{enumerate}
		\item Ein Benutzer registriert sich mit Benutzername und Passwort auf einer
			Website. Beide Werte werden an den Webserver "ubertragen.
		\item Der Server berechnet den Hashwert des Passwortes. Das Passwort wird
			verworfen, nur der Hashwert wird gespeichert.
		\item Der User m"ochte sich zu einem sp"ateren Zeitpunkt wieder einloggen.
			Daf"ur "ubermittelt er erneut das Passwort an den Server.
		\item Der Server berechnet erneut den Hashwert des Passwortes und
			vergleicht diesen mit dem zuvor gespeicherten Wert. Stimmen die beiden
			Werte "uberein, wird dem Benutzer Zugang zu den gesch"utzten Inhalten
			gew"ahrt.
\end{enumerate}

An diesem Beispiel erkennt man auch sehr gut, wie wichtig die Einwegeigenschaft
und die Kollisionsresistenz f"ur kryptologische Hashfunktionen ist. Sollte
n"amlich ein Passwort-Hash an die "Offentlichkeit gelangen (beispielsweise durch
ein Datenleck, wie sie in den letzten Jahren -- zuletzt bei Adobe -- immer
wieder geschehen sind), sollte es f"ur einen Angreifer mit praktischem Aufwand
nicht m"oglich sein, ausgehend vom Hashwert das urspr"ungliche Passwort zu
errechnen. Ebensowenig sollte es m"oglich sein, ein anderes Passwort zu finden
welches den selben Hashwert ergibt. In beiden F"allen w"are das Benutzerpasswort
dadurch kompromittiert.

MD5 gilt inzwischen als unsicher, weil erfolgreiche Angriffe auf die
Kollisionsresistenz des Algorithmus gefunden wurden. Bereits im Jahr 2006 gelang
es Forschern, MD5-Kollisionen auf einem Pentium 4 Rechner im Durchschnitt
innerhalb einer Minute zu finden\cite{crypto:stevens2006fast}. Inzwischen sind
Kollisionen auf markt"ublicher Hardware innerhalb weniger Sekunden berechenbar.
Der MD5-Algorithmus ist also h"ochstens schwach kollisionsresistent
(\ref{crypto:kollisionsresistenz}) und sollte f"ur kryptologische Anwendungen
nicht mehr eingesetzt werden.

\subsection{Brute-Force Angriff auf MD5}

W"ahrend Kollisionen f"ur frei gew"ahlte Eingabewerte wie im letzten Abschnitt
beschrieben heute problemlos berechenbar sind, ist bisher noch kein praktischer
Preimage-Angriff auf MD5 bekannt. Ein Preimage-Angriff bedeutet, dass der
Ausgabewert nicht frei gew"ahlt werden kann, sondern festgelegt ist (ein Angriff
auf die schwache Kollisionsresistenz). Wenn man nun einen Passwort-Hash
zur"uckrechnen will, ist bei einer "uberschaubaren Eingabemenge ein Brute-Force
Angriff die einfachste M"oglichkeit.

Bei einem Brute Force Angriff wird f"ur jeden Wert einer bestimmten
Eingabemenge der Hash\-wert berechnet und mit dem Zielwert verglichen. In
Pseudocode:

\begin{verbatim}
target = "47b2d986d0ae09d6504b9696e9406ca4"
for word in keyspace:
  if md5(word) == target:
    print(word)
    break
\end{verbatim}

Die Eingabemenge nennt man auch ``Keyspace''. Will man beispielsweise f"ur alle
Passw"orter bestehend aus den Klein- und Grossbuchstaben a-z / A-Z sowie den
Zahlen 0-9 mit einer L"ange von bis zu 6 Zeichen die Hashes berechnen, ergibt
dies "uber 57 Milliarden M"oglichkeiten.
\[
	\sum_{i=1}^{6} \left(26 + 26 + 10\right)^i = 57'731'386'986
\]
Hier sieht man auch schon die Schwierigkeit an der Sache, denn der Keyspace
w"achst exponentiell. Bei Erh"ohung der Maximall"ange auf 8 Zeichen sind wir schon
in der Gr"ossenordnung von ~200 Billionen.
\[
	\sum_{i=1}^{8} \left(26 + 26 + 10\right)^i = 221'919'451'578'090
\]
Im Rahmen dieser Arbeit beschr"ankten wir daher sowohl die Anzahl der m"oglichen
Zeichen wie auch die maximale L"ange der zu knackenden Passw"orter.

\subsection{Zielsetzung}

Unser Ziel im Rahmen dieser Arbeit war es, durch massiv parallele Berechnung von
MD5-Hashwerten dasjenige Eingabewort zu finden, dessen MD5-Hashwert einem zuvor
festgelegten Hashwert entspricht. Der Keyspace besteht dabei aus den
Kleinbuchstaben a-z mit einer variablen L"ange von bis zu 6 Zeichen.

Konkret haben wir uns als Ziel gesetzt in m"oglichst kurzer Zeit den MD5-Hash
des Wortes ``monkey'' (Platz 6 auf der Liste der am h"aufigsten verwendeten
Passw"orter 2012 \cite{crypto:splash2012}) zu knacken.

\begin{verbatim}
$ echo -n "monkey" | md5sum
d0763edaa9d9bd2a9516280e9044d885
\end{verbatim}

\subsection{Umsetzung mit OpenCL}

Wenn man einen MD5-Hash brute-forcen will, ben"otigt man eine massive Anzahl
komplett unabh"angiger paralleler Tasks. Die MD5-Berechnung selbst ist nicht
unabh"angig und wird deshalb nicht parallelisiert, aber mehrere MD5-Berechnungen
k"onnen nebeneinander ausgef"uhrt werden und ben"otigen keinerlei
Interprozess-Kommunikation. OpenCL ist hierf"ur also bestens geeignet.

\section{Probleme mit grossen Problemen}

\subsection{Einf"uhrung}

Auch wenn OpenCL ausdr"ucklich daf"ur entwickelt wurde, mit riesigen Clustern
von heterogenen Recheneinheiten sehr umfangreiche Probleme zu l"osen, so st"osst
man doch irgendwann an die Grenzen der Hardware oder der Implementierung.  Denn
jeder Kernel der ausgef"uhrt wird, ben"otigt Speicherplatz (Gr"osse des zur
Verf"ugung stehenden Speichers, Hardware) und muss irgendwie verwaltet werden
(Anzahl der maximal verwaltbaren Work-Items und Work-Groups, Implementierung).
Zudem ist die Anzahl Dimensionen, die von einem Kernel verarbeitet werden k"onnen,
begrenzt (Work-Item-Dimension, Hardware \& Implementierung). Deshalb folgen in
diesem Kapitel einige Betrachtungen dazu, wie man mit diesen Limitationen
umgehen kann.

Wie in der Einf"uhrung ins Problem bereits betrachtet, ergeben sich beim Zeichensatz
[a-zA-Z0-9] und einer Passwortl"ange von 8 Zeichen mehr als 200 Billionen = $2^{12}$ 
m"ogliche Kombinationen. Dieser Problemgr"osse stehen aber auf einem System mit einem 
Intel Core i5-3320M Prozessor, 8GB RAM und in einer OpenCL Workgroup maximal

\[
 N_{max} = N_{Workitems}^{wi_dim} = 8193^{3} = 5.50 * 10^{11}
\]

verwaltbare ``Problem-St"ucke'' entgegen. Trotzdem l"asst zum Beispiel die OpenCL
Implementierung von Intel auch eine gr"ossere Anzahl WorkItems problemlos zu, 
wohingegen sich die Nvidia Implementation mit einer ``Out-of-resources''-Meldung 
beendet.

Genau um diese Grenzen soll es in diesem Abschnitt gehen. Es soll aber in keinster
Weise ersch"opfend die Grenzen von OpenCL oder alle Spezifikas der 
Implementierungen eingegangen werden, sondern vielmehr f"ur das Thema sensibilisiert 
und m"ogliche Ans"atze f"ur den Umgang mit grossen Problemen in OpenCL aufgezeigt
werden, was hoffentlich dazu f"uhren wird, dass der Leser/die Leserin ein Gesp"ur 
f"ur eigene, auf die spezifische Hardware und Implementierung zugeschnittene 
Ans"atze entwickeln kann.


\subsection{Grenzen von OpenCL}

% @ Danilo: Ich würde es drin lassen. Sind zwei kurze Abschnitte, die fressen kaum
% Heu, aber ein bisschen Hintergrundinfo, denke ich kann nicht schaden.
% TODO: Ich würde auf Erweiterungen gar nicht erst eingehen. Sie sind für uns ja
% nicht sonderlich relevant.
OpenCL wurde entwickelt um trotz einem m"oglichst Plattform"ubergreifenden Ansatz 
sehr flexibel auf die Spezifika der jeweiligen Hardware reagieren zu k"onnen, was
auch das ebenfalls in OpenGL vorhandene Extension-System beinhaltet. Vor allem f"ur
% TODO: Hier ebenfalls, ich würde OpenGL gar nicht erst erwähnen, sondern ganz
% auf OpenCL fokussieren.
Einsteiger in die OpenCL/OpenGL-Welt (hier sei erw"ahnt, dass hinter beiden 
Technologien sehr "anhliche Grundkonzepte stehen) kann es dabei schwierig werden
sich im Dschungel der Hardwaredaten und M"oglichkeiten zurechtzufinden. Auf die 
wichtigsten Einstiegspunkte und die f"ur unsere Problemstellung relevanten Punkte
soll hier kurz eingegangen werden.


\subsubsection{Hardwaremerkmale abfragen}

Gerade weil OpenCL so unterschiedliche Typen Hardware unterst"utzt, von der ``normalen''
Desktop-CPU bis zu f"ur HPC Anwendungen spezialisierte Rechenkarten, gibt es einen
sehr m"achtigen Weg die jeweiligen Hardwaremerkmale abzufragen. Das kann soweit 
gehen, dass w"ahrend der Laufzeit die Hardwarekonfiguration abgefragt und das 
Problem dynamisch auf die vorhandene Hardware optimiert wird.

An dieser Stelle macht es Sinn sich nochmals vereinfacht die Top-Down-Struktur
von OpenCL (wie bereits in Abbildung \ref{hardware:opencl} gezeigt) vor Augen zu
f"uhren: \texttt{Platform $\rightarrow$ Compute Device $\rightarrow$ Compute
	Unit ($\rightarrow$ Work Group $\rightarrow$ Work Item $\rightarrow$ Work Item
Dimension)}. In dieser Reihenfolge werden auch die Hardwaremerkmale abgefragt.
OpenCL 1.2 stellt dazu folgende Funktionen zur Verf"ugung:

\begin{description}
 \item [clGetPlatformIDs()] gibt eine Liste der vorhandenen Plattformen zur"uck.
 \item [clGetPlatformInfo()] retourniert die Merkmale der aktuellen Plattform. Das heisst,
                            der Herausgeber der Implementation, die imlementierte 
                            OpenCL Version und allf"allig von der Plattform 
                            zus"atzlich unterst"utzte Erweiterungen (Das m"ussen
                            nicht die gleichen sein wie die von den jeweiligen
                            Compute Devices unterst"utzten).
 \item [clGetDeviceIDs()]   Mit der jeweiligen Plattform-ID k"onnen nun die auf der 
                            jeweiligen Plattform verf"ugbaren Compute-Devices abgefragt 
                            werden.
 \item [clGetDeviceInfo()]  Mit den so erhaltenen Device-IDs bekommt man anschliessend 
                            zum abgefragten Compute Device einen ganzen Katalog von
                            Merkmalen zur"uck, von der maximalen Anzahl von Workgroups
                            und Work-Items, "uber die Speicherkapazit"aten bis zur 
                            Clock-Frequenz und dem Hersteller der Hardware. Auf einzelne 
                            dieser Merkmale soll im Folgenden noch eingegangen werden.
\end{description}

\noindent Die genauen Parameter und R"uckgabewerte k"onnen der offiziellen
Dokumentation \cite{crypto:opencl_ref} entnommen werden.

Um das diese Begriffe etwas verst"andlicher zu machen, wird ein kurzes
Code-Beispiel f"ur einen typischen Desktop-Computer mit einer OpenCL f"ahigen
CPU und einer modernen Grafikkarte aufgef"uhrt. Es ist exemplarisch, der
Anschaulichkeit wegen in Pseudocode verfasst und repr"asentiert weder den vollen
Umfang der R"uckgabewerte noch die real ben"otigten Parameter!

\begin{small}
\begin{verbatim}
> clGetPlatformIDs()
0
1

> clGetPlatformInfo(platform=0)
Name:          Intel(R) OpenCL
Vendor:        Intel(R) Corporation
Version:       1.2
Profile:       Full
Extensions:    cl_khr_icd,cl_khr_global_int32_base_atomics,(...)

> clGetPlatformInfo(platform=1)
Name:          NVIDIA(R) OpenCL
Vendor:        NVIDIA Corp. limited
Version:       1.2
Profile:       Full
Extensions:    (...)

> clGetDeviceIDs(platform=0)
0

> clGetDeviceInfo(platform=0,device=0)
General Information:
 - Name:                 Intel(R) Core(TM) i5-3320M CPU @ 2.60GHz
 - Available:            True
 - Vendor (VID):         Intel(R) Corporation (32902)
 - Version:              OpenCL 1.2 (Build 82248)
 - Profile:              full
 - Type:                 CPU 
 - Extensions:           cl_khr_icd,cl_khr_global_int32_base_atomics,(...)
 - Endianess:            Little

Memory and Clocks
 - Clock frequency (max):2600 MHz
 - Compute units:        4
 - Global memory:        7816 MB
 - Local memory:         32768 kB, 2

Kernel properties:
 - Max param. size:      3840 B
 - Max work group size:  8192
 - Max work item dim.:   3
 - Max work item size:   [8192, 8192, 8192]

Datatypes:
 - Floating point:       Single & Double precision
 - Preferred vector size: 1 (all supported  types)
\end{verbatim}
\end{small}

\vspace{1em}

\noindent Zu einzelnen Punkten aus dem Codebeispiel hier eine kurze Erl"auterung:


\begin{description}
 \item [Version] Implementierte bzw. Unterst"utzte OpenCL Version
 \item [Profile] \texttt{full} oder \texttt{embedded} (in OpenCL 1.2)
 \item [Type]    \texttt{CPU}, \texttt{GPU} oder \texttt{ACCELERATOR}
 \item [Compute Units] Anzahl der physisch vorhandenen Compute Units. Dies ist
                 die Anzahl effektiv parallel ausgef"uhrter Kernel
 \item [Max work group size] Maximale Anzahl Work Items in einer Work Group
 \item [Max work item dim.] Maximale direkt im Work Item bearbeitbare Dimensionen, minimal 1, maximal 3
 \item [Max work item size] Maximale Anzahl von Work Items in einer Work Group nach
                 Dimensionen (Ist je nach Ger"at unterschiedlich in den verschiedenen
                 Dimensionen)
 \item [Preferred vector size] (F"ur jeden unterst"utzten Datentyp) Vektorgr"osse, 
                 die von der Hardware f"ur den jeweiligen Typ direkt (also sprich in einer 
                 Instruktion) verarbeitet werden kann.
 
\end{description}


\noindent Dabei gelten anhand der R"uckgabewerte und gem"ass der OpenCL
Spezifikation\cite{crypto:opencl_ref} folgende Regeln:

\begin{itemize}
 \item Eine Work Group wird nur auf einer Compute Unit ausgef"uhrt (1 Workgrooup = 1 
       Compute Device). Das heisst, pro Compute Unit muss eine Workgroup erstellt werden.
 \item Die Anzahl der Work-Items pro Workgroup darf insgesamt 8192 nicht "ubersteigen (global work size)
 \item Dabei d"urfen die in ``Max work item size'' angegebenen Werte in der jeweiligen 
       Dimension nicht "uberstiegen werden (local work size $[x,y,z,\ldots]$).
			 Die Summe $x + y + z$ darf dabei insgesamt nicht gr"osser werden als ``Max work group size''.
 \item Die Anzahl effektiv verwendeter Work Item Dimensionen darf im Bereich von 1 bis
       ``Max work item dim.'' liegen.
\end{itemize}


\subsubsection {Maximale Problemgr"osse einer Partikelsimulation}

% TODO luc: Aufzeigen anhand einer Partikelsimulation, 1 Pixel pro mm

\subsubsection{Maximale Problemgr"osse am Beispiel MD5 Cracking}

Am Beispiel des MD5-Crackings soll mit einer kurzen Beispielrechnung 
gezeigt werden, wie man die maximal m"ogliche Grösse eines Problems 
für die spezifische Hardware errechnen kann, die gleichzeitig der
Hardware übergeben werden kann.

Dazu treffen wir folgende Annahmen:

\begin{itemize}
 \item Wir arbeiten auf einem Device und mit einer Workgroup
 \item Der Zeichensatz soll auf [a-z] beschr"ankt sein
\end{itemize}

Die Fragestellung f"ur dieses konkrete Beispiel ist: ``Wie 
lange kann unser String werden, bevor wir weitere Massnahmen
ergreifen m"ussten?''

F"ur den Keyspace erhalten wir somit folgende Werte:
\begin{tabular}
  Stellenzahl & Keyspace \\
  5 & 1.188 * 10^7 \\
  6 & 3.089 * 10^8 \\
  7 & 8.031 * 10^9 \\
  8 & 2.088 * 10^{11} \\
  9 & 5.429 * 10^{12} 
\end{tabular}

Demgegen"uber stehen die maximale Anzahl Workitems pro Workgroup, f"ur
den bereits vorgestellten Intel Core i5 sind dies 8192. Angenommen es
wird die Dimension verwendet um den String zu berechnen (Details siehe
im n"achsten Kapitel), so ergibt sich bei 3 verwendbaren Dimensionen die 
folgende in einer Workgroup durchsuchbare Anzahl Strings:

\[
  N_{Strings} = 8192^3 = 5.498*10^{9}
\]

Das heisst, die MD5-Berechnung eines Strings mit dem (zugegeben eher 
praxisfernen) Zeichensatz [a-z] ist bereits nach einer L"ange von nur
7 Zeichen ein Problem, welches so gross ist, dass man sich "uberlegen
muss, wie man es weiter aufteilen kann. Bei einer Zeichensatzgr"osse
von $[a-zA-Z0-9] = 62$ Zeichen "ubersteigt das Problem bereits bei
$62^6 = 5.680 * 10^{10}$ die Gr"osse, die mit einer einzelnen 
Workgroup berechnet werden kann.

Beim gew"ahlten Ansatz muss zudem auch die Dimensionsgr"osse im Auge
behalten werden. Denn der zu bearbeitende String wird aus der 
Dimensionszahl berechnet wird (Details siehe im n"achsten Kapitel).
Dabei "ubersteigt bereits $26^3 = 17'576$ die Maximal zul"assige
Dimensionsgr"osse von $8192$. Das heisst effektiv kann durch diese
Beschr"ankung sogar nur ein $[26^2, 26^2, 26^2] = 6 Zeichen$ langer
String in einer Workgroup gepr"uft werden (beziehungsweise bei 
Verwendung von nur einer Dimension sogar nur $26^2 = 2 Zeichen$. 
Dieser Fall wurde aber aus wohl verst"andlichen Gr"unden gar nicht
speziell behandelt).

Dieses Tandem aus Dimensionsgr"ossen und der Gesamtzahl der Workitems
muss immer zusammen betrachtet werden. In diesem Fall war die maximale
Gr"osse einer Dimension der limitierende Faktor. Es kann aber 
durchaus auch sein, dass die Maximalgr"osse der Dimension nicht 
"uberschritten wird, aber bereits zu viele Workitems vorhanden sind
(siehe dazu die Beschreibung zu den Hardwaremerkmalen).

Jetzt gibt es aber durchaus Unterschiede in der Behandlung von ``zu
grossen Problem'' durch die verschiedenen Implementationen. W"ahrend
die Intel Implementation Dimensionen gr"osser als die deklarierten
8192 pro Dimension zul"asst, verabschiedet sich die Nvidia Implementation
mit einem ``Out-of-Resources'' Fehler, sobald in einer Dimension die 
Maximalanzahl von 8192 "uberschritten wird. Das genaue Verhalten der
jeweils verwendeten Implementation sollte vorg"angig abgekl"art oder
einfach mal ausprobiert werden. Trotzdem kann es lohnenswert sein, sich
bei solch umfangreichen Problemen ein wenig mehr Gedanken zur Aufteilung
des Problems zu machen, nicht zuletzt, weil das, wie wir im n"achsten
Kapitel sehen werden, einen grossen Einfluss auf die Geschwindigkeit des
Totals der Rechnungen haben kann.

\subsection{Aufteilung von grossen Problemen}

In diesem Kapitel werden einige Techniken beschrieben, mit denen ein 
grosses Problem weiter portioniert werden kann, so dass es in die 
Hardware und die Implementierung ``passt''. 
Denn wie im letzten Kapitel aufgezeigt wurde sollte man sp"atestens dann
beginnen sich Gedanken zur Problemgr"osse zu machen, wenn man an die 
Grenzen der Hardware st"osst. Es lohnt sich aber auch, wie in diesem 
Kapitel auch gezeigt werden soll, bereits vorg"angig mal anzuschauen
wo man an die Grenzen der Hardware st"osst, beziehungsweise wie das
Problem besser aufgeteilt werden kann, um nicht zuletzt auch die 
Hardware optimal ausn"utzen zu k"onnen.

Speziell soll dabei auf die folgenden Techniken eingegangen werden:

\begin{itemize}
 \item Mehrere Workgroups verwenden
 \item Virtuelle Dimensionsvergr"osserung
 \item Mehr als eine Berechnung pro Kernel
 \item Mehrfacher, parametrisierter ``Anwurf'' der OpenCL Maschine
\end{itemize}

Dazu ist anzumerken, dass hier auf diejenigen Techniken eingegangen
wird, die auch im Zuge der Implementierung des MD5-Cracking Projekts
ausprobiert oder evaluiert wurden. Das heisst, die Liste erhebt weder
die den Anspruch auf Vollst"andigkeit noch auf die Brauchbarkeit f"ur
ein spezielles Problem. Wir hoffen aber, dem Leser ein paar Ideen
in die Hand zu geben, mit denen er seine eigene Anwendung hoffentlich
weiter optimieren kann.


\subsubsection{Mehrere Workgroups verwenden}

Im gemachten Beispiel im vorherigen Abschnitt wurde davon ausgegangen,
dass nur eine Workgroup verwendet wird. Diese Vorgabe wurde zum einen
der Anschaulichkeit halber gemacht, um die Komplexit"at nicht h"oher zu
treiben als sowieso schon notwendig, zum anderen besitzt besagtes Ger"at
mit dem Intel Core i5 Prozessor nur ein von OpenCL direkt ansprechbares
Compute Device (Implementierungsspezifisch). Im Normalfall besitzt jeder
moderne Desktop Computer und die meisten Notebooks mindestens zwei 
OpenCL f"ahige Ger"ate, namentlich die CPU und die Grafikkarte. 
Vorausgesetzt die entsprechenden Treiber sind installiert, k"onnen alle
diese Ger"ate f"ur die Berechnungen verwendet werden.

Genau hier kommt auch das Thema ``Mehrere Workgroups'' ins Spiel, denn
eine Workgroup kann jeweils nur ein Ger"at ansprechen. Will man also
nicht nur die CPU \textit{oder} die Grafikkarte verwenden, sondern die 
CPU \textit{und} die Grafikkarte parallel verwenden, m"ussen unabh"angig
von der Problemgr"osse mehrere Workgroups erzeugt werden.

Zugegeben, das hat nun nicht unbedingt direkt etwas mit der weiteren 
Aufteilung des Problems zu tun, trotzdem kann diese Technik auch bei
Problemen verwendet werden, welche die Grenzen einer Workgroup sprengen.
Das kann aber als Variante des Punktes ``Mehrfacher, parametrisierter
``Anwurf'' der OpenCL Maschine'' gesehen werden. Wirklich Sinn macht 
diese Variante vor allem wenn mehrere Compute Devices zur Verf"ugung
stehen. Hier ist anzumerken, dass je nach Implementation und 
verwendeter Frameworks die Aufteilung in Workgroups auch automatisch
vorgenommen wird, wenn nichts explizit angegeben wird. Aus den im
n"achsten Absatz genannten Problem der unterschiedlichen Laufzeiten
sollte um das Optimum aus der Hardware zu holen wenn m"oglich selbst
aufgeteilt werden.

Denn insbesondere unterschiedliche Ger"ate rechnen
auch unterschiedlich schnell. Es wird nicht einfach sein, 
beim ersten Versuch die Problem-``H"appchen'' so zu portionieren, dass
die Berechnungen auf beiden Compute Devices ungef"ahr "ahnlich lang 
laufen. Dabei geht es nicht um Minuten, es kann durchaus sein, dass 
die Portion welche auf der GPU gerechnet wurde, nach 30 Minuten bereits
fertig ist, diejenige, welche die CPU "ubernimmt aber 3 Stunden dauert.
Somit ist die GPU also 2.5 Stunden unbesch"aftigt rumgestanden. Hier
empfiehlt es sich bei unbekannter Hardware mit kleinen Portionen zu 
beginnen, die Durchlaufzeiten zu messen und erst dann zu Entscheiden,
wie die weitere Aufteilung aussehen soll. Um eine gute Aussagekraft
zu erhalten, sollten die ersten Portionen auch nicht zu klein sein,
irgendwo zwischen 10-100 Berechnungen sollten die meisten Unw"agbarkeiten
ausb"ugeln. Dabei kann durchaus auch Iterativ vorgegangen werden, um
eine m"oglichst optimale Aufteilung zu erreichen und der Ansatz ist
auch leicht automatisierbar.

Zusammengefasst gilt f"ur die Erh"ohung der Anzahl Workgroups:

\begin{itemize}
 \item Zur Ausn"utzung von mehreren Compute Devices auf einer Plattform
       muss zwingend mit mindestens einer Workgroup pro Compute Device
       gearbeitet werden. So kann die Geschwindigkeit grunds"atzlich
       erh"oht werden.
 \item Synchronisation / Abbruch "uber Workgroup-Grenzen hinweg ist 
       nicht direkt m"oglich.
 \item Als Konsequenz k"onnen unterschiedliche Laufzeiten in den 
       verschiedenen Compute Devices unter Umst"anden zu 
       ungewollten Idle-Zeiten f"ur die schnelleren Compute Devices 
       f"uhren. Eine sorgf"altige, an die Geschwindigkeit der 
       Compute Devices angepasste Aufteilung der Workitems ist n"otig.
\end{itemize}



\subsubsection{Virtuelle Dimensionsvergr"osserung}

Wird davon ausgegangen, dass in unserem speziellen Beispiel die Dimensionen
zur "Ubergabe des zu bearbeitenden Strings verwendet wird, w"are eigentlich
bei einem String mit 3 Zeichen bereits schluss (bei einer maximalen Dimension
von 3). Da aber bei der Dimension und einer Alphabetgr"osse effektiv nur die 
Ziffern 1..26 verwendet werden, wären \[ 8192 - 26 = 8156 \] m"ogliche 
Punkte im Gitter quasi verschwendet worden. Hier kann eine Virtuelle 
Dimensionsvergr"osserung helfen, indem zur Berechnung des Problempunktes 
nach der Formel \[ B^{n} \] vorgegangen wird, wobei \[ B \] die Gr"osse der
ben"otigten Dimension darstellt (in unserem Fall \[ 26 \]) und \[ n \] die
Anzahl der virtuell ben"otigten Dimensionen. Wir haben vorg"angig in diesem
Skript bereits implizit mit dieser Technik gearbietet, um auch mit realen
Stringl"angen rechnen zu k"onnen.

Im Kernel selbst kann man bei gegebenem Punkt die Dimensionen mit 
Modulo-Arithmetik wie folgt berechnen:

\begin{tabular}{2}
  \[n\]   & \[dim \% B \] \\
  \[n-1\] & \[(dim/B) \% B\] \\
  \[n-2\] & \[(dim/B^{2}) \% B\] \\
  \vdots  & \ldots
\end{tabular}

Hierzu ist zusagen, dass Divisonen und auch die Modulo-Bildung auch auf
modernen Floating-Point Units sehr rechenintensiv ist (Anzahl ben"otigte 
Taktzyklen immer \[ >> 1 \]). Trotzdem kann dieses Vorgehen bei einer 
begrenzten Dimensionsgr"osse des Problems aber vielen potentiellen 
Dimensionen sinn machen, insbesondere wenn eine Dimensionsberechnung mit
Modulo-Arithmetik f"ur mehrere Berechnungen verwendet werden kann
(siehe n"achsten Abschnitt).

Sollte die Hardware eine gr"ossere Dimensionensanzahl unterst"utzen als 
3, was vor allem wegen der Verwendung von OpenCL in 3D-Simulationen
mehr oder weniger Standard ist, oder falls \[ B < n \] sein sollte, 
kann man sich auch "uberlegen, ob \[ n \] und \[ B \] allenfalls vertauscht
werden k"onnten.

Zusammengefasst gilt f"ur die virtuelle Dimensionsvergr"osserung:

\begin{itemize}
 \item Bei einem Problem, welches nur eine kleine Anzahl Punkte pro 
       Dimension ben"otigt, aber viele Dimensionen hat, kann mit der
       virtuellen Dimensionsvergr"osserung eine ``Verschwendung'' von
       m"oglichen Workitems in einer Workgroup verhindert werden.
 \item Die Berechnung der einzelnen Punkte in den virtuellen 
       Dimensionen ist aber sehr kostspielig im Bezug auf daf"ur notwendige
       Rechenzeit.
 \item Diesem Problem kann begegnet werden, indem pro Dimensionsrechnung
       mehrere Rechnungen ausgef"uhrt werden. (siehe n"achster Abschnitt)
\end{itemize}


\subsubsection{Mehr als eine Berechnung pro Kernel}

Ist der Initialisierungsaufwand in einem Kernel verglichen mit der eigentlichen
Berechnung relativ gross und zeitaufwendig, so kann es sich lohnen, mehr als 
eine Berechnung pro Kernel durchf"uhren zu lassen. Speziell dann wenn der 
Arbeitsbereich zum Beispiel in einer Schleife abgearbeitet werden kann, kann
mit dieser Technik sehr viel Performance rausgeholt werden.

Denn das Vorgehen, dass ein Kernel nur jeweils eine einzelne Rechnung macht, 
ist zwar von der Systematik in der Problemaufteilung wohl durchaus sinnvoll 
und auch einfach zu verstehen. Zudem muss man sich bei der Aufteilung der
Arbeitspakete deutlich mehr Gedanken machen, um zu verhindern, dass keine
L"ucken entstehen.

Doch gerade bei nicht sehr aufw"andigen Berechnungen pro Kernel, was wohl 
eher die Regel sein wird, ist die Initialisierung im Vergleich zum eigentlichen
Rechenvorgang sehr zeitintensiv, und ``stielt'' so einen Teil der m"oglichen
Rechenkapazit"at. Macht zum Beispiel die Initialisierung 20 \% der gesamten
Rechenzeit aus, so ist ein Optimierungspotential von nahezu demselben Faktor
m"oglich, wenn statt einer 10 Berechnungen in einem Kernel durchgef"uhrt 
werden. Gerade bei der im vorherigen Absatz vorgestellten Methode k"onnen
durchaus auch deutlich gr"ossere Geschwndigkeitsvorteile herausschauen, denn
Modulo und Divisons Operationen f"uhren die Listen der kostspieligsten 
Instruktionen im Sinne von Rechenzeitverbrauch deutlich an.

Im aktuellen Beispiel des MD5-Cracking konnte durch die Einf"uhrung zweier
Schleifen, welche f"ur die letzten zwei Zeichen des Strings insgesamt 
\[ 26^2 = 676 \] Berechnungen und Stringpr"ufungen durchf"uhrten, die 
maximale L"ange des berechenbaren Strings ohne gross sp"urbare zus"atzliche
Rechenzeit erweitert werden.

\begin{itemize}
 \item Ist die Initialisierung eines Kernels "anhlich rechenintensiv wie die
       tats"achliche Berechnung selber (bis ca. Faktor 1 : 10) und das 
       Arbeitspaket durch einfache Schleifen ``erweiterbar'', so lohnt
       es sich dar"uber Gedanken zu machen, ob man mehr als eine Berechnung
       im Kernel machen soll.
 \item Doch steigen die Anforderungen an die Aufteilung der Arbeitspakete:
       Soll nur in eine Dimension erweitert werden? Und in welche? Was 
       passiert an den Grenzen, wenn die Anzahl Berechnungen im Kernel die 
       noch zu berechnende Anzahl Punkte "ubersteigt?
 \item Auf unterschiedlicher Hardware kann das Verh"altnis Initialisierung : 
       Rechenzeit durchaus deutliche Unterschiede zeigen. Die Aufteilung
       lohnt sich nicht in jedem Fall und muss auf die jeweilige Hardware
       zugeschnitten werden.
\end{itemize}




\subsubsection{Mehrfacher parametrisierter ``Anwurf'' der OpenCL Maschine}

St"osst man trotz der in den vorherigen Abschnitten betrachteten Techniken
an die Grenzen einer Workgroup oder sogar der Gesamtzahl der verf"ugbaren
Workgroups, oder will man vor allem bei Verwendung mehrerer Workgroups 
nach einer gewissen Anzahl von Berechnungen pr"ufen ob das Ergebnis schon
vorliegt, so muss man die OpenCL Maschine mehrmals aufrufen. Dabei kann 
ein Offset definiert werden, der dann bei der Berechnung des Arbeitspakets
im Kernel zu der Dimensionszahl hinzu gez"ahlt wird.

"Ubergeben werden kann dieser Offset mit einer globalen Variable, die vom
Rahmenprogramm direkt gesetzt wird, welches auch die Workgroups vorbereitet 
und die Kernel startet. Damit kann das Programm beliebig weiter ausgebaut
werden, jedoch kostet der ``Anwurf'' der OpenCL Maschine auch Rechenzeit.
F"ur eine kleine Menge von Workitems mit jeweils kurzer Rechenzeit pro Kernel
lohnt sich der Aufwand somit im Normalfall kaum. 

Anders sieht die 
Ausgangslage aus, wenn die Berechnungen je Kernel sehr aufw"andig oder
die Workgroup sehr gross wird, insbesondere dann, wenn nicht einfach von 
A bis Z durchgerechnet werden soll, sondern gelegentlich auf eine 
(Workgroup "ubergreifende) Abbruchbedingung gepr"uft werden soll. Denn
"uber die Workgroup hinaus kann kein Abbruch (und auch keine anderen 
Signale) signalisiert werden. Es muss gewartet werden, bis die restlichen
Workgroups fertig sind mit ihrem Arbeitspaket, und erst dann kann "uber
die ganze ``Maschine'' hinaus gepr"uft werden, ob das Abbruchkriterium
erf"ullt ist und anschliessend die Maschine weitergelaufen lassen 
beziehungsweise definitiv angehalten werden.

Wie im letzten Abschnitt anget"ont kann es sich vor allem bei heterogenen 
Umgebungen von Compute Devices auch lohnen, schon relativ fr"uh die 
Berechnungen nochmals anzuhalten, diesmal aber nicht mit dem Ziel auf eine
Abbruchbedingung zu pr"ufen, sondern die Workitems anhand der gemessenen
Laufzeiten der Workgroups m"oglichst effizient auf die Compute Devices
aufzuteilen.

\begin{itemize}
 \item Die OpenCL-Maschine mehrfach anzuhalten und wieder anzuwerfen 
       kann aus unterschiedlichen Gr"unden Sinn machen: Zum einen
       wenn das Problem so gross wird, dass es nicht mehr sinnvoll auf 
       die verf"ugbare Menge von Workgroups und Workitems je Workgroup
       aufgeteilt werden kann; Wenn das Problem eine definierte 
       Abbruchbedingung hat, die man regelm"assig und Workgroup-
       "Ubergreifend pr"ufen m"ochte; Und w"ahrend dem Einmessvorgang
       zur m"oglichst optimalen Aufteilung der Arbeitspakete f"ur die 
       jeweilige Performance des Compute Devices.
 \item Der Overhead f"ur den Anwurf der OpenCL Maschine kann aber im 
       vergleich zur Arbeitszeit eines Kernels sehr gross sein. Es soll
       also von dieser Technik trotz der genannten Vorteile und 
       M"oglichkeiten nur mit Bedacht gebrauch gemacht werden, und 
       (ausser allenfalls bei der Einmessung) die OpenCL Maschine
       m"oglichst lange selbst rechnen lassen.
\end{itemize}




% TODO Lukas: Codebeispiel für Globale OpenCL Variable



\section{L"osungsansatz}

% TODO danilo: Ev Bezug auf vorherige Section

Um den Brute-Force-Knacker zu implementieren haben wir uns f"ur folgenden
L"osungsansatz entschieden:

\begin{itemize}
	\item Jedes m"ogliche Eingabe-Wort wird einem Kernel zugewiesen
	\item Jeder Kernel berechnet den MD5-Hash f"ur genau ein Wort
	\item Das Eingabe-Wort wird innerhalb des Kernels aus der mehrdimensionalen
		Global ID hergeleitet.
	\item Der errechnete Hash wird innerhalb des Kernels mit dem Ziel-Hash
		verglichen. Sofern die zwei Werte "ubereinstimmen, wird das Wort in den
		Result-Buffer geschrieben.
	\item Der Einfachheit halber wird im Erfolgsfall kein vorzeitiger Abbruch
		durchgef"uhrt, stattdessen wird der ganze Keyspace durchprobiert.
	\item Nachdem alle m"oglichen Hash-Werte berechnet wurden, wird der
		Result-Buffer vom Hauptprogramm ausgelesen und angezeigt.
\end{itemize}

\noindent Zusammengefasst besteht der Ablauf aus drei Phasen: Init (CPU),
Calculate (GPU), Collect (CPU).

\begin{figure}[H]
	\centering
	\input{crypto/programm-struktur}
	\caption{L"osungsansatz Programmstruktur}
	\label{img:crypto:programm-struktur}
\end{figure}

\subsection{Herleitung Wort aus Global ID}

Irgendwie muss nun jeder Kernel herausfinden, welches Wort er hashen soll. Eine
"Ubergabe des zu hashenden Wortes vom Hauptprogramm an jeden Kernel via Shared
Memory w"are ineffizient und w"urde nur unn"otigen I/O verursachen. Es muss also
eine bessere L"osung gefunden werden.

Der Vorteil an unserem Problem ist, dass der Keyspace f"ur die m"oglichen
Eingabewerte einen Linearen Raum darstellt. Es liegt also nahe, das Wort aus der
Global ID herzuleiten. Die Global ID ist eine $n$-Dimensionale nat"urliche Zahl,
welche jedem Kernel von OpenCL zugewiesen wird. Der Wertebereich bewegt sich
dabei in Einerschritten von $(0, ..., 0)$ bis $(n, ..., n)$. Dabei ist $n$ die
\textit{Work Size} f"ur die entsprechende Dimension.

\subsubsection{Naiver Ansatz}

Ein naiver Ansatz w"are nun, dass die jede Dimension der Global ID einem
m"oglichen Zeichen des Eingabewortes entspricht. Die Dimensionszahl entspricht
dann der Anzahl Zeichen im Eingabewort. Um diesen Ansatz zu verdeutlichen,
nachfolgend ein Beispiel f"ur ein Eingabewort mit der L"ange 3 und a-z als
m"ogliches Alphabet:

\begin{small}
\begin{verbatim}
>>> id = (22, 19, 5)
>>> alphabet = "abcdefghijklmnopqrstuvwxyz"
>>> word = alphabet[id[0]] + alphabet[id[1]] + alphabet[id[2]]
>>> print(word)
wtf
\end{verbatim}
\end{small}

\noindent Das sieht zwar auf den ersten Blick nach einem guten Ansatz aus, jedoch ergibt
sich dabei das erste Problem: Die Anzahl m"oglicher Dimensionen darf gem"ass
OpenCL Standard\cite{crypto:stephan2011kryptographie} maximal 3 sein. Das
bedeutet, dass man mit diesem Ansatz nur W"orter mit einer L"ange von bis zu 3
Zeichen knacken kann. Man muss also einen Weg finden, diese Dimensionen
irgendwie zu vergr"ossern.

\subsubsection{Virtuelle Dimensionen}

Eine M"oglichkeit dazu ist die Einf"uhrung virtueller Dimensionen. Dabei werden
mehrere Dimensionen durch Multiplikation der Keyspace-Gr"osse in eine einzelne
``Virtuelle Dimension'' gepackt. Konkret sieht das so aus:

\begin{itemize}
	\item Dimension bei Wort-L"ange 1: $(26,)$
	\item Dimension bei Wort-L"ange 3: $(26, 26, 26)$
	\item Dimension bei Wort-L"ange 4: $(26^2, 26, 26) = (676, 26, 26)$
	\item Dimension bei Wort-L"ange 7: $(26^3, 26^2, 26^2) = (17576, 676, 676)$
\end{itemize}

\noindent Aus diesen Werten kann dann der Buchstabe $c_n$ an Position $n$ mithilfe von
Modulo-Arithmetik aus der Work Size $d$abgeleitet werden:
\[
	c_n = \frac{d}{26^n} \enskip\%\enskip 26
\]
Um nun den entsprechenden ASCII-Buchstaben zu erhalten, muss man lediglich
diesen Wert $c_n$ um 97 erh"ohen.

Damit das ganze etwas einfacher zu implementieren ist, f"uhren wir zus"atzlich
das Konzept eines ``Triplets'' ein. Die Triplet-ID ergibt sich, wenn man die
Buchstaben des Wortes in Dreiergruppen aufteilt (Sliding Window Algorithmus).

\begin{figure}[H]
	\centering
	\input{crypto/triplets}
	\caption{Aufteilung des Wortes in Triplets}
	\label{img:crypto:triplets}
\end{figure}

\noindent In OpenCL C sieht das Ganze folgendermassen aus:

\begin{small}
\begin{verbatim}
// Initialize private variables
__private char string[MAX_PW_LEN];
__private unsigned int global_id;
__private unsigned char triplet_id;

for (int i = 0; i < 3; i++) {

  // Get global ID for dimension i
  global_id = get_global_id(i);

  // Loop through triplets
  for (triplet_id = 0; triplet_id <= (len - 1) / 3; triplet_id += 1) {
    string[triplet_id * 3 + i] = 0x61 + ((int)(global_id / pown(26., triplet_id)) % 26);
  }

}
\end{verbatim}
\end{small}

\subsection{Berechnen des MD5-Wertes}

- Wie wird der MD5-Hash berechnet?

\subsection{Init, Collect}

- Wie werden die Kernel initialisiert? Wie wird der Rückgabewert entgegen
genommen?

\section{Implementationseigenheiten}

(Ev. als Subsection von "L"osungsansatz")
- Limitationen der gew"ahlten L"osung
- Was k"onnte man verbessern?
- ...

\section{Resultate}

- Performancemessungen
- Bedeutung f"ur Umgang mit Passw"ortern

\printbibliography[heading=subbibliography]
\end{refsection}
